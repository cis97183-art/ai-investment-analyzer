import streamlit as st
import pandas as pd
import google.generativeai as genai
from langchain.chains import LLMChain
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
import plotly.graph_objects as go
import json
from datetime import datetime
import re

# --- å¾ç¨ç«‹æª”æ¡ˆå°å…¥ ETF è¦å‰‡ ---
from etf_rules import ETF_PROMPT_FRAMEWORK

# --- å°ˆæ¡ˆèªªæ˜ ---
# é€™å€‹æ‡‰ç”¨ç¨‹å¼æ˜¯ä¸€å€‹ AI é©…å‹•çš„å€‹äººåŒ–æŠ•è³‡çµ„åˆå»ºæ§‹èˆ‡åˆ†æç³»çµ±ã€‚
# æ ¸å¿ƒåŠŸèƒ½æ˜¯åˆ©ç”¨ä¸€å€‹è©³ç´°çš„ã€Œå°è‚¡æŠ•è³‡çµ„åˆé¢¨éšªåå¥½å®šç¾©è¦å‰‡ã€æ¡†æ¶ï¼Œ
# çµåˆå¤§å‹èªè¨€æ¨¡å‹ (LLM)ï¼Œç‚ºä½¿ç”¨è€…ç”Ÿæˆç¬¦åˆå…¶é¢¨éšªåå¥½èˆ‡æŠ•è³‡ç›®æ¨™çš„å°è‚¡æŠ•è³‡çµ„åˆå»ºè­°ï¼Œ
# æ”¯æ´ç´”å€‹è‚¡ã€ç´” ETF ä»¥åŠæ··åˆå‹æŠ•è³‡çµ„åˆã€‚

# --- Google API é‡‘é‘°è¨­å®š ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except (KeyError, Exception) as e:
    st.error("éŒ¯èª¤ï¼šè«‹ç¢ºèªä½ çš„ Google API é‡‘é‘°å·²åœ¨ `.streamlit/secrets.toml` ä¸­æ­£ç¢ºè¨­å®šã€‚")
    st.info("è¨­å®šæ•™å­¸ï¼šåœ¨å°ˆæ¡ˆè³‡æ–™å¤¾ä¸­å»ºç«‹ `.streamlit` è³‡æ–™å¤¾ï¼Œä¸¦åœ¨å…¶ä¸­æ–°å¢ `secrets.toml` æª”æ¡ˆï¼Œå…§å®¹ç‚ºï¼š`GOOGLE_API_KEY = \"ä½ çš„é‡‘é‘°\"`")
    st.stop()

# --- AI Prompt æ¡†æ¶ (å€‹è‚¡è¦å‰‡) ---
STOCK_PROMPT_FRAMEWORK = """
### å°è‚¡æŠ•è³‡çµ„åˆé¢¨éšªåå¥½å®šç¾©è¦å‰‡ (AI Prompt Framework for Taiwan Market)
| è¦å‰‡ç¶­åº¦ (Rule Dimension) | ä¿å®ˆå‹ (Conservative) | ç©©å¥å‹ (Balanced) | ç©æ¥µå‹ (Aggressive) |
|---|---|---|---|
| **1. ä¸»è¦æŠ•è³‡ç›®æ¨™** | è³‡æœ¬ä¿å€¼ï¼Œè¿½æ±‚ç©©å®šè‚¡åˆ©ç¾é‡‘æµèˆ‡çµ•å°å ±é…¬ã€‚ | è¿½æ±‚è³‡æœ¬é•·æœŸæº«å’Œå¢å€¼ï¼Œå…¼é¡§é¢¨éšªæ§åˆ¶ã€‚ | è¿½æ±‚è³‡æœ¬æœ€å¤§åŒ–å¢é•·ï¼Œé¡˜æ„æ‰¿å—è¼ƒå¤§æ³¢å‹•ä»¥æ›å–é«˜é¡å›å ±ã€‚ |
| **2. æŠ•è³‡çµ„åˆ Beta å€¼** | 0.5 - 0.8 | 0.8 - 1.1 | > 1.1 |
| **3. é æœŸå¹´åŒ–æ³¢å‹•ç‡** | 8% - 13% | 13% - 20% | > 20% |
| **4. ç›®æ¨™å¤æ™®æ¯”ç‡**| > 1.0 | > 0.7 | > 0.5 |
| **5. a) HHI æŒ‡æ•¸** | < 500 | 500 - 800 | > 800 |
| **5. b) å–®ä¸€ç”¢æ¥­æ¬Šé‡** | < 20% | < 30% | < 40% |
| **6. a) å…¬å¸è¦æ¨¡** | å¤§å‹è‚¡ç‚ºä¸» (å¸‚å€¼ > 2000å„„) | å¤§å‹ã€ä¸­å‹è‚¡ç‚ºä¸» (å¸‚å€¼ > 500å„„) | å¯åŒ…å«ä¸­å°å‹è‚¡ |
| **6. b) ç”¢æ¥­é¢¨æ ¼** | å´é‡é˜²ç¦¦å‹ç”¢æ¥­ (é‡‘èã€é›»ä¿¡ã€å¿…éœ€æ¶ˆè²») | å‡è¡¡é…ç½®æ ¸å¿ƒé›»å­è‚¡èˆ‡å‚³ç”¢é¾é ­è‚¡ã€‚ | å´é‡é«˜æˆé•·é›»å­è‚¡ (åŠå°é«”ã€AIã€ICè¨­è¨ˆ) |
| **6. c) è²¡å‹™å“è³ª** | é«˜æ®–åˆ©ç‡ã€ä½è² å‚µã€ç©©å®šç¾é‡‘æµã€‚ | å…¼å…·ç©©å®šç›ˆåˆ©èˆ‡ç‡Ÿæ”¶æˆé•·æ½›åŠ›ã€‚ | é«˜ç‡Ÿæ”¶å¢é•·ã€é«˜æ¯›åˆ©ã€‚ |
| **7. å¸‚å ´æ¿å¡Š** | ä»¥**é›†ä¸­å¸‚å ´(ä¸Šå¸‚)**ç‚ºä¸»ã€‚ | å¯é©åº¦ç´å…¥**æ«ƒè²·ä¸­å¿ƒ(ä¸Šæ«ƒ)**ç¸¾å„ªè‚¡ã€‚ | å¯æé«˜æ«ƒè²·ä¸­å¿ƒ(ä¸Šæ«ƒ)æ¯”é‡ã€‚ |
"""

# --- RAG æ ¸å¿ƒé‚è¼¯ ---

def get_llm_chain(prompt_template):
    """å»ºç«‹ä¸€å€‹ LLMChain ä¾†è™•ç†æˆ‘å€‘çš„è«‹æ±‚ã€‚"""
    model = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest",
                                 temperature=0.2,
                                 model_kwargs={"response_format": {"type": "json_object"}})
    prompt = PromptTemplate.from_template(prompt_template)
    chain = LLMChain(llm=model, prompt=prompt)
    return chain

def _clean_and_parse_json(raw_text: str):
    """æ¸…ç†ä¸¦è§£æ LLM çš„ JSON è¼¸å‡ºï¼Œå¢å¼·ç©©å®šæ€§ã€‚"""
    match = re.search(r"```(json)?\s*({.*?})\s*```", raw_text, re.DOTALL)
    if match:
        clean_text = match.group(2)
    else:
        start_index = raw_text.find('{')
        end_index = raw_text.rfind('}')
        if start_index != -1 and end_index != -1 and end_index > start_index:
            clean_text = raw_text[start_index:end_index+1]
        else:
            clean_text = raw_text
    try:
        return json.loads(clean_text)
    except json.JSONDecodeError as e:
        st.error("JSON è§£æå¤±æ•—ï¼Œå³ä½¿åœ¨æ¸…ç†å¾Œä¹Ÿæ˜¯å¦‚æ­¤ã€‚")
        st.write("ä»¥ä¸‹æ˜¯ AI å›å‚³çš„åŸå§‹æ–‡å­—ï¼Œé€™å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼š")
        st.code(raw_text, language="text")
        raise e

# --- å ±å‘Šç”Ÿæˆèˆ‡å¯è¦–åŒ– ---

def generate_portfolio(portfolio_type, risk_profile, investment_amount):
    """æ ¹æ“šçµ„åˆé¡å‹ç”ŸæˆæŠ•è³‡å ±å‘Š"""
    
    prompt_templates = {
        "ç´”å€‹è‚¡": """
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£è‚¡å¸‚æŠ•è³‡çµ„åˆç¶“ç†ã€‚è«‹æ ¹æ“šã€Œå°è‚¡æŠ•è³‡çµ„åˆé¢¨éšªåå¥½å®šç¾©è¦å‰‡ã€ä»¥åŠä½¿ç”¨è€…è³‡è¨Šï¼Œç‚ºä»–é‡èº«æ‰“é€ ä¸€å€‹ç´”å°è‚¡çš„æŠ•è³‡çµ„åˆã€‚
        **ä»»å‹™**: æŒ‘é¸ 5 åˆ° 8 æ”¯ç¬¦åˆ '{risk_profile}' è¦å‰‡çš„å°è‚¡ï¼Œåˆ†é…æ¬Šé‡ï¼Œä¼°ç®—æŒ‡æ¨™ï¼Œä¸¦ä»¥æŒ‡å®šçš„ JSON æ ¼å¼å›å‚³ã€‚
        **è¦å‰‡**: \n{stock_rules}
        **ä½¿ç”¨è€…è³‡è¨Š**: é¢¨éšªåå¥½: {risk_profile}, æŠ•å…¥è³‡é‡‘: {investment_amount}
        **ä½ çš„è¼¸å‡ºå¿…é ˆæ˜¯ç´”ç²¹çš„ JSON æ ¼å¼ï¼Œç›´æ¥ä»¥ '{{' é–‹å§‹ï¼Œä»¥ '}}' çµæŸã€‚çµæ§‹å¦‚ä¸‹:**
        **é‡è¦**: `portfolio_metrics` ä¸­çš„æ‰€æœ‰å€¼éƒ½å¿…é ˆæ˜¯ç´”ç²¹çš„æ•¸å­—æˆ–æŒ‡å®šçš„ç™¾åˆ†æ¯”å­—ä¸²ï¼Œä¸å¾—åŒ…å«ä»»ä½•æ‹¬è™Ÿæˆ–é¡å¤–èªªæ˜æ–‡å­—ã€‚
        {{
          "summary": {{"title": "ç‚º{risk_profile}æŠ•è³‡è€…è¨­è¨ˆçš„ã€ç´”å€‹è‚¡ã€‘æŠ•è³‡çµ„åˆ", "overview": "...", "generated_date": "{current_date}"}},
          "portfolio_metrics": {{
              "beta": "<ä¸€å€‹æ•¸å­—ï¼Œä¾‹å¦‚ 1.2>", 
              "annual_volatility": "<ä¸€å€‹ç™¾åˆ†æ¯”å­—ä¸²ï¼Œä¾‹å¦‚ '21%'>", 
              "sharpe_ratio": "<ä¸€å€‹æ•¸å­—ï¼Œä¾‹å¦‚ 0.6>", 
              "hhi_index": "<ä¸€å€‹æ•¸å­—ï¼Œä¾‹å¦‚ 850>"
          }},
          "holdings": [
            {{"ticker": "...", "name": "...", "industry": "...", "weight": 0.25, "rationale": "..."}}
          ]
        }}
        """,
        "ç´” ETF": """
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£ ETF æŠ•è³‡çµ„åˆç¶“ç†ã€‚è«‹æ ¹æ“šã€Œå°è‚¡ ETF ç¯©é¸è¦å‰‡ã€ä»¥åŠä½¿ç”¨è€…è³‡è¨Šï¼Œç‚ºä»–é‡èº«æ‰“é€ ä¸€å€‹ç´”å°è‚¡ ETF çš„æŠ•è³‡çµ„åˆã€‚
        **ä»»å‹™**: æŒ‘é¸ 3 åˆ° 5 æ”¯ç¬¦åˆ '{risk_profile}' è¦å‰‡çš„å°è‚¡ ETFï¼Œåˆ†é…æ¬Šé‡ï¼Œä¼°ç®—æŒ‡æ¨™ï¼Œä¸¦ä»¥æŒ‡å®šçš„ JSON æ ¼å¼å›å‚³ã€‚
        **è¦å‰‡**: \n{etf_rules}
        **ä½¿ç”¨è€…è³‡è¨Š**: é¢¨éšªåå¥½: {risk_profile}, æŠ•å…¥è³‡é‡‘: {investment_amount}
        **ä½ çš„è¼¸å‡ºå¿…é ˆæ˜¯ç´”ç²¹çš„ JSON æ ¼å¼ï¼Œç›´æ¥ä»¥ '{{' é–‹å§‹ï¼Œä»¥ '}}' çµæŸã€‚çµæ§‹å¦‚ä¸‹:**
        **é‡è¦**: `portfolio_metrics` ä¸­çš„æ‰€æœ‰å€¼éƒ½å¿…é ˆæ˜¯ç´”ç²¹çš„æ•¸å­—æˆ–æŒ‡å®šçš„ç™¾åˆ†æ¯”å­—ä¸²ï¼Œä¸å¾—åŒ…å«ä»»ä½•æ‹¬è™Ÿæˆ–é¡å¤–èªªæ˜æ–‡å­—ã€‚
        {{
          "summary": {{"title": "ç‚º{risk_profile}æŠ•è³‡è€…è¨­è¨ˆçš„ã€ç´” ETFã€‘æŠ•è³‡çµ„åˆ", "overview": "...", "generated_date": "{current_date}"}},
          "portfolio_metrics": {{
              "beta": "<ä¸€å€‹æ•¸å­—ï¼Œä¾‹å¦‚ 0.9>", 
              "annual_volatility": "<ä¸€å€‹ç™¾åˆ†æ¯”å­—ä¸²ï¼Œä¾‹å¦‚ '15%'>", 
              "sharpe_ratio": "<ä¸€å€‹æ•¸å­—ï¼Œä¾‹å¦‚ 0.8>"
          }},
          "holdings": [
            {{"ticker": "...", "name": "...", "etf_type": "...", "weight": 0.4, "rationale": "..."}}
          ]
        }}
        """,
        "æ··åˆå‹": """
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£è³‡ç”¢é…ç½®å°ˆå®¶ã€‚è«‹æ¡ç”¨ã€Œæ ¸å¿ƒ-è¡›æ˜Ÿã€ç­–ç•¥ï¼Œç‚ºä½¿ç”¨è€…å»ºç«‹ä¸€å€‹æ··åˆå‹æŠ•è³‡çµ„åˆã€‚
        **ä»»å‹™**:
        1. **æ ¸å¿ƒéƒ¨ä½ (70% è³‡é‡‘)**: æ ¹æ“šã€Œå°è‚¡ ETF ç¯©é¸è¦å‰‡ã€ï¼Œç‚º '{risk_profile}' é¢¨éšªåå¥½æŒ‘é¸ 1-2 æ”¯ ETFã€‚
        2. **è¡›æ˜Ÿéƒ¨ä½ (30% è³‡é‡‘)**: æ ¹æ“šã€Œå°è‚¡æŠ•è³‡çµ„åˆé¢¨éšªåå¥½å®šç¾©è¦å‰‡ã€ï¼Œç‚º '{risk_profile}' é¢¨éšªåå¥½æŒ‘é¸ 3-5 æ”¯å€‹è‚¡ã€‚
        3. **æ ¼å¼åŒ–è¼¸å‡º**: å°‡çµæœä»¥æŒ‡å®šçš„ JSON æ ¼å¼å›å‚³ã€‚
        **å€‹è‚¡è¦å‰‡**: \n{stock_rules}
        **ETF è¦å‰‡**: \n{etf_rules}
        **ä½¿ç”¨è€…è³‡è¨Š**: é¢¨éšªåå¥½: {risk_profile}, æŠ•å…¥è³‡é‡‘: {investment_amount}
        **ä½ çš„è¼¸å‡ºå¿…é ˆæ˜¯ç´”ç²¹çš„ JSON æ ¼å¼ï¼Œç›´æ¥ä»¥ '{{' é–‹å§‹ï¼Œä»¥ '}}' çµæŸã€‚çµæ§‹å¦‚ä¸‹:**
        **é‡è¦**: `portfolio_metrics` ä¸­çš„æ‰€æœ‰å€¼éƒ½å¿…é ˆæ˜¯ç´”ç²¹çš„æ•¸å­—æˆ–æŒ‡å®šçš„ç™¾åˆ†æ¯”å­—ä¸²ï¼Œä¸å¾—åŒ…å«ä»»ä½•æ‹¬è™Ÿæˆ–é¡å¤–èªªæ˜æ–‡å­—ã€‚
        {{
          "summary": {{"title": "ç‚º{risk_profile}æŠ•è³‡è€…è¨­è¨ˆçš„ã€æ ¸å¿ƒ-è¡›æ˜Ÿæ··åˆå‹ã€‘æŠ•è³‡çµ„åˆ", "overview": "...", "generated_date": "{current_date}"}},
          "portfolio_metrics": {{
              "beta": "<ä¸€å€‹æ•¸å­—ï¼Œä¾‹å¦‚ 1.0>", 
              "annual_volatility": "<ä¸€å€‹ç™¾åˆ†æ¯”å­—ä¸²ï¼Œä¾‹å¦‚ '17%'>", 
              "sharpe_ratio": "<ä¸€å€‹æ•¸å­—ï¼Œä¾‹å¦‚ 0.75>"
          }},
          "core_holdings": [{{"ticker": "...", "name": "...", "weight": 0.7, "rationale": "..."}}],
          "satellite_holdings": [{{"ticker": "...", "name": "...", "weight": 0.1, "rationale": "..."}}]
        }}
        """
    }

    prompt_template = prompt_templates[portfolio_type]
    chain = get_llm_chain(prompt_template)
    today_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    input_data = {
        "stock_rules": STOCK_PROMPT_FRAMEWORK,
        "etf_rules": ETF_PROMPT_FRAMEWORK,
        "risk_profile": risk_profile,
        "investment_amount": f"{investment_amount:,.0f}",
        "current_date": today_str
    }
    
    response = chain.invoke(input_data)
    return _clean_and_parse_json(response['text'])


def display_report(report_data, investment_amount):
    """ä»¥åœ–æ–‡ä¸¦èŒ‚çš„æ–¹å¼å‘ˆç¾å ±å‘Š"""
    
    st.header(report_data['summary']['title'])
    st.info(f"å ±å‘Šç”Ÿæˆæ—¥æœŸï¼š{report_data['summary']['generated_date']}")
    
    st.subheader("ğŸ“ˆ æŠ•è³‡çµ„åˆç¸½è¦½")
    st.write(report_data['summary']['overview'])
    
    st.subheader("ğŸ“Š æ ¸å¿ƒé¢¨éšªæŒ‡æ¨™")
    metrics = report_data['portfolio_metrics']
    
    # ** å„ªåŒ–é» 1: ä½¿ç”¨ç°¡æ½”çš„æ¨™ç±¤ä¸¦å‹•æ…‹èª¿æ•´æ¬„ä½ **
    metric_labels = {
        'beta': "Beta å€¼",
        'annual_volatility': "å¹´åŒ–æ³¢å‹•ç‡",
        'sharpe_ratio': "å¤æ™®æ¯”ç‡",
        'hhi_index': "HHI é›†ä¸­åº¦"
    }
    
    cols = st.columns(len(metrics))
    for i, (key, value) in enumerate(metrics.items()):
        label = metric_labels.get(key, key.replace('_', ' ').title())
        if key == 'hhi_index':
            try:
                value = f"{float(value):.0f}"
            except (ValueError, TypeError):
                value = str(value)
        cols[i].metric(label, value)

    st.write("---")

    # æ ¹æ“šå ±å‘Šé¡å‹ï¼Œæº–å‚™ DataFrame
    if 'core_holdings' in report_data: # æ··åˆå‹
        core_df = pd.DataFrame(report_data['core_holdings'])
        core_df['é¡å‹'] = 'æ ¸å¿ƒ (ETF)'
        sat_df = pd.DataFrame(report_data['satellite_holdings'])
        sat_df['é¡å‹'] = 'è¡›æ˜Ÿ (å€‹è‚¡)'
        df = pd.concat([core_df, sat_df], ignore_index=True)
        st.subheader("è¦–è¦ºåŒ–åˆ†æï¼šæ•´é«”è³‡ç”¢é…ç½®")
    else: # ç´”å€‹è‚¡æˆ–ç´” ETF
        df = pd.DataFrame(report_data['holdings'])
        st.subheader("è¦–è¦ºåŒ–åˆ†æ")

    df['è³‡é‡‘åˆ†é… (TWD)'] = (df['weight'] * investment_amount).round(0)
    df['æ¬Šé‡ (%)'] = (df['weight'] * 100).round(2)
    
    # ** å„ªåŒ–é» 2: æ¢å¾©é•·æ¢åœ–ä¸¦èˆ‡åœ“é¤…åœ–ä¸¦æ’ **
    chart1, chart2 = st.columns(2)

    with chart1:
        fig_pie = go.Figure(data=[go.Pie(
            labels=df['name'], values=df['weight'], hole=.3,
            textinfo='percent+label', hoverinfo='label+percent+value',
            texttemplate='%{label}<br>%{percent:.1%}',
        )])
        fig_pie.update_layout(title_text='æŒè‚¡æ¬Šé‡åˆ†é…', showlegend=False, margin=dict(l=0, r=0, t=40, b=0))
        st.plotly_chart(fig_pie, use_container_width=True)

    with chart2:
        # æ™ºæ…§åˆ¤æ–·è¦ç”¨å“ªå€‹æ¬„ä½ä¾†ç•«é•·æ¢åœ–
        if 'industry' in df.columns and df['industry'].notna().any():
            group_col = 'industry'
            chart_title = 'ç”¢æ¥­æ¬Šé‡åˆ†ä½ˆ'
        elif 'etf_type' in df.columns and df['etf_type'].notna().any():
            group_col = 'etf_type'
            chart_title = 'ETF é¡å‹åˆ†ä½ˆ'
        else:
            group_col = None

        if group_col:
            grouped = df.groupby(group_col)['weight'].sum().reset_index()
            fig_bar = go.Figure(data=[go.Bar(
                x=grouped[group_col],
                y=grouped['weight'],
                text=(grouped['weight']*100).apply(lambda x: f'{x:.1f}%'),
                textposition='auto',
            )])
            fig_bar.update_layout(
                title_text=chart_title,
                xaxis_title=None,
                yaxis_title="æ¬Šé‡",
                yaxis_tickformat='.0%',
                margin=dict(l=0, r=0, t=40, b=0)
            )
            st.plotly_chart(fig_bar, use_container_width=True)
        else:
            st.info("æ­¤æŠ•è³‡çµ„åˆç„¡é©ç”¨çš„åˆ†é¡å¯ä¾›ç¹ªè£½é•·æ¢åœ–ã€‚")


    st.write("---")
    
    # è©³ç´°æŒè‚¡è¡¨æ ¼
    st.subheader("ğŸ“ è©³ç´°æŒè‚¡èˆ‡è³‡é‡‘è¨ˆç•«")

    # ** å„ªåŒ–é» 3: çµ±ä¸€è¡¨æ ¼é¡¯ç¤ºï¼Œåªé¡¯ç¤ºä¸€å€‹æ¬Šé‡æ¬„ä½ **
    display_cols = ['ticker', 'name']
    # æ™ºæ…§åˆ¤æ–·è¦é¡¯ç¤º industry é‚„æ˜¯ etf_type
    if 'industry' in df.columns and df['industry'].notna().any():
        display_cols.append('industry')
    if 'etf_type' in df.columns and df['etf_type'].notna().any():
        display_cols.append('etf_type')
        
    display_cols.extend(['æ¬Šé‡ (%)', 'è³‡é‡‘åˆ†é… (TWD)', 'rationale'])
    
    # ç¢ºä¿æ‰€æœ‰è¦é¡¯ç¤ºçš„æ¬„ä½éƒ½å­˜åœ¨
    final_cols = [col for col in display_cols if col in df.columns]

    st.dataframe(
        df[final_cols],
        use_container_width=True,
        hide_index=True,
        column_config={
            "æ¬Šé‡ (%)": st.column_config.ProgressColumn(
                "æ¬Šé‡ (%)", format="%.2f%%", min_value=0, max_value=100,
            ),
            "è³‡é‡‘åˆ†é… (TWD)": st.column_config.NumberColumn(
                "è³‡é‡‘åˆ†é… (TWD)", format="NT$ %'d"
            ),
            "rationale": st.column_config.TextColumn("ç°¡è¦ç†ç”±", width="large")
        }
    )

def handle_follow_up_question(question, context):
    """è™•ç†å¾ŒçºŒå•é¡Œ"""
    prompt_template = """
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£è‚¡å¸‚æŠ•è³‡çµ„åˆç¶“ç†ã€‚ä½¿ç”¨è€…å·²ç¶“æ”¶åˆ°ä½ å…ˆå‰å»ºç«‹çš„æŠ•è³‡çµ„åˆå ±å‘Šï¼Œç¾åœ¨ä»–æœ‰å¾ŒçºŒå•é¡Œã€‚
    è«‹æ ¹æ“šä½ å…ˆå‰æä¾›çš„å ±å‘Šå…§å®¹ï¼Œä»¥åŠä½¿ç”¨è€…çš„å•é¡Œï¼Œæä¾›ç°¡æ½”ã€å°ˆæ¥­çš„å›ç­”ã€‚
    **å…ˆå‰å ±å‘Šçš„å…§å®¹æ‘˜è¦ (JSON):**
    {context}
    **ä½¿ç”¨è€…çš„å•é¡Œ:**
    {question}
    è«‹ç›´æ¥å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚
    """
    model = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0.5)
    prompt = PromptTemplate.from_template(prompt_template)
    chain = LLMChain(llm=model, prompt=prompt)

    response = chain.invoke({"context": json.dumps(context, ensure_ascii=False), "question": question})
    return response['text']


# --- å»ºç«‹ä½¿ç”¨è€…ä»‹é¢ (UI) ---

st.set_page_config(page_title="AI æŠ•è³‡çµ„åˆå»ºæ§‹ç³»çµ±", layout="wide")
st.title("ğŸ’¡ AI å€‹äººåŒ–æŠ•è³‡çµ„åˆå»ºæ§‹èˆ‡åˆ†æç³»çµ± (V5)")
st.markdown("æœ¬ç³»çµ±æ¡ç”¨å°ˆæ¥­é¢¨éšªæ¡†æ¶ï¼Œç”± AI ç‚ºæ‚¨é‡èº«æ‰“é€ å°ˆå±¬çš„**ç´”å€‹è‚¡ã€ç´” ETF** æˆ– **æ ¸å¿ƒ-è¡›æ˜Ÿæ··åˆå‹** å°è‚¡æŠ•è³‡çµ„åˆã€‚")

if 'portfolio_generated' not in st.session_state:
    st.session_state.portfolio_generated = False
if 'report_data' not in st.session_state:
    st.session_state.report_data = None
if 'messages' not in st.session_state:
    st.session_state.messages = []

# --- è¼¸å…¥ä»‹é¢ ---
with st.sidebar:
    st.header("ğŸ‘¤ æ‚¨çš„æŠ•è³‡è¨­å®š")
    portfolio_type_input = st.radio(
        "1. è«‹é¸æ“‡æŠ•è³‡çµ„åˆé¡å‹",
        ("ç´”å€‹è‚¡", "ç´” ETF", "æ··åˆå‹"),
        index=0,
        captions=("åƒ…å«å€‹è‚¡", "åƒ…å« ETF", "ETF ç‚ºæ ¸å¿ƒï¼Œå€‹è‚¡ç‚ºè¡›æ˜Ÿ")
    )
    risk_profile_input = st.selectbox(
        "2. è«‹é¸æ“‡æ‚¨çš„é¢¨éšªåå¥½", 
        ('ç©æ¥µå‹', 'ç©©å¥å‹', 'ä¿å®ˆå‹'), 
        index=0, 
        help="ç©æ¥µå‹è¿½æ±‚é«˜å›å ±ï¼›ç©©å¥å‹å¹³è¡¡é¢¨éšªèˆ‡å›å ±ï¼›ä¿å®ˆå‹æ³¨é‡è³‡æœ¬ä¿å€¼ã€‚"
    )
    investment_amount_input = st.number_input(
        "3. è«‹è¼¸å…¥æ‚¨é è¨ˆæŠ•å…¥çš„ç¸½è³‡é‡‘ (æ–°å°å¹£)", 
        min_value=10000, 
        value=100000, 
        step=10000
    )
    analyze_button = st.button("ğŸš€ ç”Ÿæˆæˆ‘çš„æŠ•è³‡çµ„åˆ", type="primary", use_container_width=True)
    st.info("å…è²¬è²æ˜ï¼šæœ¬ç³»çµ±åƒ…ç‚ºAIè¼”åŠ©åˆ†æå·¥å…·ï¼Œæ‰€æœ‰è³‡è¨Šèˆ‡å»ºè­°åƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡æ±ºç­–çš„ä¾æ“šã€‚æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°ã€‚")

# --- ä¸»ç•«é¢é¡¯ç¤ºå€ ---
if analyze_button:
    st.session_state.messages = []
    
    with st.spinner(f"æ­£åœ¨ç‚ºæ‚¨é€™ä½ã€Œ{risk_profile_input}ã€æŠ•è³‡è€…å»ºæ§‹å°ˆå±¬çš„ã€{portfolio_type_input}ã€‘æŠ•è³‡çµ„åˆ..."):
        try:
            report = generate_portfolio(portfolio_type_input, risk_profile_input, investment_amount_input)
            st.session_state.report_data = report
            st.session_state.portfolio_generated = True
        except json.JSONDecodeError:
            st.error("AI å›æ‡‰çš„æ ¼å¼ç„¡æ³•è¢«æ­£ç¢ºè§£æï¼Œè«‹æª¢æŸ¥ä¸Šæ–¹ç”±ç³»çµ±æä¾›çš„è©³ç´°éŒ¯èª¤è³‡è¨Šã€‚")
            st.session_state.portfolio_generated = False
        except Exception as e:
            st.error(f"åˆ†æéç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ï¼")
            st.exception(e)
            st.session_state.portfolio_generated = False

if st.session_state.portfolio_generated:
    display_report(st.session_state.report_data, investment_amount_input)
    
    st.write("---")
    st.subheader("ğŸ’¬ æå•èˆ‡äº’å‹•èª¿æ•´")
    st.info("å°é€™å€‹æŠ•è³‡çµ„åˆæœ‰ä»»ä½•ç–‘å•å—ï¼Ÿæˆ–è€…æƒ³åšäº›å¾®èª¿ï¼Ÿè«‹åœ¨ä¸‹æ–¹æå‡ºæ‚¨çš„å•é¡Œã€‚")

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("ä¾‹å¦‚ï¼šç‚ºä»€éº¼é¸æ“‡ 0050ï¼Ÿ æˆ–è€… å¯ä»¥æŠŠåŠå°é«”å€‹è‚¡æ›æˆåˆ¥çš„å—ï¼Ÿ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
            response = handle_follow_up_question(prompt, st.session_state.report_data)
            st.session_state.messages.append({"role": "assistant", "content": response})
            with st.chat_message("assistant"):
                st.markdown(response)
else:
    st.info("è«‹åœ¨å·¦å´å´é‚Šæ¬„è¨­å®šæ‚¨çš„æŠ•è³‡åå¥½èˆ‡è³‡é‡‘ï¼Œç„¶å¾Œé»æ“ŠæŒ‰éˆ•é–‹å§‹ã€‚")


