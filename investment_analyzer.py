import streamlit as st
import pandas as pd
import google.generativeai as genai
from langchain.chains import LLMChain
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
import plotly.graph_objects as go
import json
from datetime import datetime
import re
import yfinance as yf

# --- å°å…¥å°ˆæ¡ˆæ¨¡çµ„ ---
from etf_rules import ETF_PROMPT_FRAMEWORK
from prompts import get_data_driven_prompt_templates, STOCK_PROMPT_FRAMEWORK
# [æ–°] å°å…¥ API ç¯©é¸å™¨ï¼Œå–ä»£èˆŠçš„ data_fetcher å’Œ screener
from api_screener import screen_stocks_api

# --- å°ˆæ¡ˆèªªæ˜ ---
st.set_page_config(page_title="å³æ™‚è¦å‰‡é©…å‹• AI æŠ•è³‡çµ„åˆç³»çµ±", layout="wide")
st.title("ğŸš€ å³æ™‚è¦å‰‡é©…å‹• AI æŠ•è³‡çµ„åˆå»ºæ§‹ç³»çµ± (V3 API)")
st.markdown("æœ¬ç³»çµ±æ¡ç”¨**å³æ™‚è¦å‰‡é©…å‹•ç¯©é¸ (Real-time Rule-Driven Screening)**ã€‚ç•¶æ‚¨é»æ“Šç”ŸæˆæŒ‰éˆ•æ™‚ï¼Œç³»çµ±æœƒ**å³æ™‚èª¿ç”¨å¤–éƒ¨çš„ã€Œè‚¡ç¥¨ç¯©é¸å™¨ APIã€**ï¼Œå°‡æ‚¨çš„é¢¨éšªåå¥½è½‰æ›ç‚ºå…·é«”åƒæ•¸ç™¼é€ï¼Œç›´æ¥ç²å–ç¬¦åˆç•¶ä¸‹å¸‚å ´æ¢ä»¶çš„è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨ï¼Œå†äº¤ç”± AI é€²è¡Œè³ªåŒ–åˆ†æèˆ‡çµ„åˆå»ºæ§‹ã€‚")


# --- Google API é‡‘é‘°è¨­å®š ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except (KeyError, Exception) as e:
    st.error("éŒ¯èª¤ï¼šè«‹ç¢ºèªä½ çš„ Google API é‡‘é‘°å·²åœ¨ `.streamlit/secrets.toml` ä¸­æ­£ç¢ºè¨­å®šã€‚")
    st.info("è¨­å®šæ•™å­¸ï¼šåœ¨å°ˆæ¡ˆè³‡æ–™å¤¾ä¸­å»ºç«‹ `.streamlit` è³‡æ–™å¤¾ï¼Œä¸¦åœ¨å…¶ä¸­æ–°å¢ `secrets.toml` æª”æ¡ˆï¼Œå…§å®¹ç‚ºï¼š`GOOGLE_API_KEY = \"ä½ çš„é‡‘é‘°\"`")
    st.stop()


# --- RAG æ ¸å¿ƒé‚è¼¯ ---
def get_llm_chain(prompt_template):
    """åˆå§‹åŒ–ä¸¦å›å‚³ä¸€å€‹ LangChain LLMChainã€‚"""
    model = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest",
                                 temperature=0.2,
                                 model_kwargs={"response_format": {"type": "json_object"}})
    prompt = PromptTemplate.from_template(prompt_template)
    chain = LLMChain(llm=model, prompt=prompt)
    return chain

def _clean_and_parse_json(raw_text: str):
    """æ¸…ç†ä¸¦è§£æ LLM åŸå§‹è¼¸å‡ºä¸­çš„ JSON å­—ä¸²ã€‚"""
    match = re.search(r"```(json)?\s*({.*?})\s*```", raw_text, re.DOTALL)
    if match:
        clean_text = match.group(2)
    else:
        start_index = raw_text.find('{')
        end_index = raw_text.rfind('}')
        if start_index != -1 and end_index != -1 and end_index > start_index:
            clean_text = raw_text[start_index:end_index+1]
        else:
            clean_text = raw_text
    try:
        return json.loads(clean_text)
    except json.JSONDecodeError as e:
        st.error("JSON è§£æå¤±æ•—ã€‚")
        st.code(raw_text, language="text")
        raise e

@st.cache_data(ttl=1800) # å¿«å–æ•¸æ“š 30 åˆ†é˜
def get_stock_details(tickers: list[str]) -> pd.DataFrame:
    """
    [æ–°] æ ¹æ“š API å›å‚³çš„ ticker åˆ—è¡¨ï¼Œä½¿ç”¨ yfinance ç²å–è©³ç´°æ•¸æ“šã€‚
    """
    all_info = []
    progress_bar = st.progress(0, text="æ­£åœ¨ä¸‹è¼‰ API ç¯©é¸çµæœçš„è©³ç´°è‚¡ç¥¨æ•¸æ“š...")
    
    for i, ticker_id in enumerate(tickers):
        try:
            ticker_obj = yf.Ticker(ticker_id)
            info = ticker_obj.info
            
            if not info or info.get('marketCap') is None:
                raise ValueError(f"ç¼ºå°‘ {ticker_id} çš„é—œéµæ•¸æ“šã€‚")

            filtered_info = {
                'tickerId': ticker_id,
                'shortName': info.get('shortName'),
                'industry': info.get('industry'),
                'marketCap': info.get('marketCap'),
                'beta': info.get('beta'),
                'averageVolume': info.get('averageVolume10day'),
                'trailingPE': info.get('trailingPE'),
                'dividendYield': info.get('dividendYield'),
            }
            all_info.append(filtered_info)
        except Exception as e:
            st.warning(f"ä¸‹è¼‰ {ticker_id} æ•¸æ“šæ™‚å‡ºéŒ¯: {e}")
        
        progress_bar.progress((i + 1) / len(tickers), text=f"æ­£åœ¨ä¸‹è¼‰ {i+1}/{len(tickers)}: {ticker_id} ...")

    progress_bar.empty()
    
    if not all_info:
        return pd.DataFrame()

    df = pd.DataFrame(all_info).set_index('tickerId')
    df.dropna(subset=['marketCap', 'beta', 'shortName'], inplace=True)
    return df

# --- å ±å‘Šç”Ÿæˆèˆ‡å¯è¦–åŒ– ---
def generate_portfolio(portfolio_type, risk_profile, investment_amount):
    """[V3 API] æ ¹æ“š API ç¯©é¸çµæœç”ŸæˆæŠ•è³‡å ±å‘Š"""

    if portfolio_type in ["ç´”å€‹è‚¡", "æ··åˆå‹"]:
        # --- æ­¥é©Ÿ 1: èª¿ç”¨ API å–å¾—è‚¡ç¥¨åˆ—è¡¨ ---
        candidate_tickers = screen_stocks_api(risk_profile)
        
        if not candidate_tickers:
            st.error("API æœªå›å‚³ä»»ä½•ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ï¼Œç„¡æ³•ç”ŸæˆæŠ•è³‡çµ„åˆã€‚")
            return None

        # --- æ­¥é©Ÿ 2: ç²å–é€™äº›è‚¡ç¥¨çš„è©³ç´°æ•¸æ“š ---
        with st.spinner("æ­¥é©Ÿ 2/3: æ­£åœ¨å¾ yfinance ç²å– API ç¯©é¸çµæœçš„è©³ç´°æ•¸æ“š..."):
            candidate_df = get_stock_details(candidate_tickers)
            if candidate_df.empty:
                st.error("ç„¡æ³•ç‚º API å›å‚³çš„è‚¡ç¥¨ç²å–è©³ç´°æ•¸æ“šã€‚")
                return None
            
            candidate_data_for_llm = candidate_df[['shortName', 'marketCap', 'beta', 'trailingPE', 'dividendYield']].to_csv(index=True)

        # --- æ­¥é©Ÿ 3: å°‡çµæœäº¤çµ¦ AI åˆ†æ ---
        with st.spinner("æ­¥é©Ÿ 3/3: å·²ç²å–æ•¸æ“šï¼æ­£åœ¨å°‡å€™é¸åå–®äº¤ç”± AI é€²è¡Œæœ€çµ‚è³ªåŒ–åˆ†æ..."):
            prompt_templates = get_data_driven_prompt_templates()
            prompt_template = prompt_templates[portfolio_type]
            chain = get_llm_chain(prompt_template)
            
            input_data = {
                "stock_rules": STOCK_PROMPT_FRAMEWORK,
                "etf_rules": ETF_PROMPT_FRAMEWORK,
                "risk_profile": risk_profile,
                "investment_amount": f"{investment_amount:,.0f}",
                "current_date": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥"),
                "candidate_stocks_csv": candidate_data_for_llm
            }
            response = chain.invoke(input_data)
            return _clean_and_parse_json(response['text'])

    else: # ç´” ETF æµç¨‹ (ä¸éœ€ç¶“éå€‹è‚¡ API)
        with st.spinner("æ­£åœ¨ç‚ºæ‚¨å»ºæ§‹ç´” ETF æŠ•è³‡çµ„åˆ..."):
            prompt_templates = get_data_driven_prompt_templates()
            prompt_template = prompt_templates[portfolio_type]
            chain = get_llm_chain(prompt_template)
            input_data = {
                "etf_rules": ETF_PROMPT_FRAMEWORK,
                "risk_profile": risk_profile,
                "investment_amount": f"{investment_amount:,.0f}",
                "current_date": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
            }
            response = chain.invoke(input_data)
            return _clean_and_parse_json(response['text'])


def display_report(report_data, investment_amount):
    """ä»¥åœ–æ–‡ä¸¦èŒ‚çš„æ–¹å¼å‘ˆç¾å ±å‘Š"""
    
    st.header(report_data['summary']['title'])
    st.info(f"å ±å‘Šç”Ÿæˆæ—¥æœŸï¼š{report_data['summary']['generated_date']}")
    
    st.subheader("ğŸ“ˆ æŠ•è³‡çµ„åˆç¸½è¦½")
    st.write(report_data['summary']['overview'])
    
    st.subheader("ğŸ“Š æ ¸å¿ƒé¢¨éšªæŒ‡æ¨™")
    metrics = report_data['portfolio_metrics']
    metric_labels = {'beta': "Beta å€¼", 'annual_volatility': "å¹´åŒ–æ³¢å‹•ç‡", 'sharpe_ratio': "å¤æ™®æ¯”ç‡", 'hhi_index': "HHI é›†ä¸­åº¦"}
    
    cols = st.columns(len(metrics))
    for i, (key, value) in enumerate(metrics.items()):
        label = metric_labels.get(key, key.replace('_', ' ').title())
        if key == 'hhi_index':
            try: value = f"{float(value):.0f}"
            except (ValueError, TypeError): value = str(value)
        cols[i].metric(label, value)

    st.write("---")

    if 'core_holdings' in report_data:
        core_df = pd.DataFrame(report_data['core_holdings'])
        core_df['é¡å‹'] = 'æ ¸å¿ƒ (ETF)'
        sat_df = pd.DataFrame(report_data['satellite_holdings'])
        sat_df['é¡å‹'] = 'è¡›æ˜Ÿ (å€‹è‚¡)'
        df = pd.concat([core_df, sat_df], ignore_index=True)
        st.subheader("è¦–è¦ºåŒ–åˆ†æï¼šæ•´é«”è³‡ç”¢é…ç½®")
    else:
        df = pd.DataFrame(report_data['holdings'])
        st.subheader("è¦–è¦ºåŒ–åˆ†æ")

    df['weight'] = pd.to_numeric(df['weight'], errors='coerce')
    df.dropna(subset=['weight'], inplace=True)
    if not df.empty and df['weight'].sum() > 0:
        df['weight'] = df['weight'] / df['weight'].sum()

    df['è³‡é‡‘åˆ†é… (TWD)'] = (df['weight'] * investment_amount).round(0)
    df['æ¬Šé‡ (%)'] = (df['weight'] * 100).round(2)
    
    chart1, chart2 = st.columns(2)

    with chart1:
        fig_pie = go.Figure(data=[go.Pie(
            labels=df['name'], values=df['weight'], hole=.3,
            textinfo='percent+label', hoverinfo='label+percent+value',
            texttemplate='%{label}<br>%{percent:.1%}',
        )])
        fig_pie.update_layout(title_text='æŒè‚¡æ¬Šé‡åˆ†é…', showlegend=False, margin=dict(l=0, r=0, t=40, b=0))
        st.plotly_chart(fig_pie, use_container_width=True)

    with chart2:
        group_col = None
        if 'industry' in df.columns and df['industry'].notna().any():
            group_col = 'industry'
            chart_title = 'ç”¢æ¥­æ¬Šé‡åˆ†ä½ˆ'
        elif 'etf_type' in df.columns and df['etf_type'].notna().any():
            group_col = 'etf_type'
            chart_title = 'ETF é¡å‹åˆ†ä½ˆ'

        if group_col:
            grouped = df.groupby(group_col)['weight'].sum().reset_index()
            fig_bar = go.Figure(data=[go.Bar(
                x=grouped[group_col], y=grouped['weight'],
                text=(grouped['weight']*100).apply(lambda x: f'{x:.1f}%'),
                textposition='auto',
            )])
            fig_bar.update_layout(title_text=chart_title, xaxis_title=None, yaxis_title="æ¬Šé‡", yaxis_tickformat='.0%', margin=dict(l=0, r=0, t=40, b=0))
            st.plotly_chart(fig_bar, use_container_width=True)

    st.write("---")
    st.subheader("ğŸ“ è©³ç´°æŒè‚¡èˆ‡è³‡é‡‘è¨ˆç•«")
    display_cols = ['ticker', 'name']
    if 'industry' in df.columns and df['industry'].notna().any(): display_cols.append('industry')
    if 'etf_type' in df.columns and df['etf_type'].notna().any(): display_cols.append('etf_type')
    display_cols.extend(['æ¬Šé‡ (%)', 'è³‡é‡‘åˆ†é… (TWD)', 'rationale'])
    final_cols = [col for col in display_cols if col in df.columns]

    st.dataframe(df[final_cols], use_container_width=True, hide_index=True,
        column_config={
            "æ¬Šé‡ (%)": st.column_config.ProgressColumn("æ¬Šé‡ (%)", format="%.2f%%", min_value=0, max_value=100),
            "è³‡é‡‘åˆ†é… (TWD)": st.column_config.NumberColumn("è³‡é‡‘åˆ†é… (TWD)", format="NT$ %'d"),
            "rationale": st.column_config.TextColumn("ç°¡è¦ç†ç”±", width="large")
        })

def handle_follow_up_question(question, context):
    """è™•ç†å¾ŒçºŒå•é¡Œ"""
    prompt_template = """
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£è‚¡å¸‚æŠ•è³‡çµ„åˆç¶“ç†ã€‚ä½¿ç”¨è€…å·²ç¶“æ”¶åˆ°ä½ å…ˆå‰å»ºç«‹çš„æŠ•è³‡çµ„åˆå ±å‘Šï¼Œç¾åœ¨ä»–æœ‰å¾ŒçºŒå•é¡Œã€‚
    è«‹æ ¹æ“šä½ å…ˆå‰æä¾›çš„å ±å‘Šå…§å®¹ï¼Œä»¥åŠä½¿ç”¨è€…çš„å•é¡Œï¼Œæä¾›ç°¡æ½”ã€å°ˆæ¥­çš„å›ç­”ã€‚
    **å…ˆå‰å ±å‘Šçš„å…§å®¹æ‘˜è¦ (JSON):** {context}
    **ä½¿ç”¨è€…çš„å•é¡Œ:** {question}
    è«‹ç›´æ¥å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚
    """
    model = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0.5)
    prompt = PromptTemplate.from_template(prompt_template)
    chain = LLMChain(llm=model, prompt=prompt)
    response = chain.invoke({"context": json.dumps(context, ensure_ascii=False), "question": question})
    return response['text']

# --- UI ---
if 'portfolio_generated' not in st.session_state: st.session_state.portfolio_generated = False
if 'report_data' not in st.session_state: st.session_state.report_data = None
if 'messages' not in st.session_state: st.session_state.messages = []

with st.sidebar:
    st.header("ğŸ‘¤ æ‚¨çš„æŠ•è³‡è¨­å®š")
    portfolio_type_input = st.radio("1. è«‹é¸æ“‡æŠ•è³‡çµ„åˆé¡å‹", ("ç´”å€‹è‚¡", "ç´” ETF", "æ··åˆå‹"), index=0)
    risk_profile_input = st.selectbox("2. è«‹é¸æ“‡æ‚¨çš„é¢¨éšªåå¥½", ('ç©æ¥µå‹', 'ç©©å¥å‹', 'ä¿å®ˆå‹'), index=0)
    investment_amount_input = st.number_input("3. è«‹è¼¸å…¥æ‚¨é è¨ˆæŠ•å…¥çš„ç¸½è³‡é‡‘ (æ–°å°å¹£)", min_value=10000, value=100000, step=10000)
    analyze_button = st.button("ğŸš€ ç”Ÿæˆæˆ‘çš„æŠ•è³‡çµ„åˆ", type="primary", use_container_width=True)
    st.info("å…è²¬è²æ˜ï¼šæœ¬ç³»çµ±åƒ…ç‚ºAIè¼”åŠ©åˆ†æå·¥å…·ï¼Œæ‰€æœ‰è³‡è¨Šèˆ‡å»ºè­°åƒ…ä¾›åƒè€ƒã€‚æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°ã€‚")

if analyze_button:
    st.session_state.messages = []
    st.session_state.report_data = None
    st.session_state.portfolio_generated = False
    
    report = generate_portfolio(portfolio_type_input, risk_profile_input, investment_amount_input)
    if report:
        st.session_state.report_data = report
        st.session_state.portfolio_generated = True

if st.session_state.portfolio_generated:
    display_report(st.session_state.report_data, investment_amount_input)
    st.write("---")
    st.subheader("ğŸ’¬ æå•èˆ‡äº’å‹•èª¿æ•´")
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]): st.markdown(message["content"])
        
    if prompt := st.chat_input("å°é€™å€‹æŠ•è³‡çµ„åˆæœ‰ä»»ä½•ç–‘å•å—ï¼Ÿ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)
        
        with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
            response = handle_follow_up_question(prompt, st.session_state.report_data)
            st.session_state.messages.append({"role": "assistant", "content": response})
            with st.chat_message("assistant"): st.markdown(response)
else:
    st.info("è«‹åœ¨å·¦å´å´é‚Šæ¬„è¨­å®šæ‚¨çš„æŠ•è³‡åå¥½èˆ‡è³‡é‡‘ï¼Œç„¶å¾Œé»æ“ŠæŒ‰éˆ•é–‹å§‹ã€‚")
