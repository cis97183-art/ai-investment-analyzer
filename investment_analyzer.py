import streamlit as st
import pandas as pd
import numpy as np
import google.generativeai as genai
from langchain.chains import LLMChain
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
import plotly.graph_objects as go
import plotly.express as px
import json
from datetime import datetime
import re
import os
import time

# --- å°å…¥å°ˆæ¡ˆæ¨¡çµ„ ---
# å‡è¨­ update_database, etf_rules, prompts, data_loader, screener éƒ½åœ¨åŒç´šç›®éŒ„
from update_database import main as run_db_update
from etf_rules import ETF_PROMPT_FRAMEWORK
from prompts import get_data_driven_prompt_templates, STOCK_PROMPT_FRAMEWORK
from data_loader import load_and_merge_data
from screener import screen_stocks

# --- å°ˆæ¡ˆèªªæ˜ ---
st.set_page_config(page_title="å°è‚¡åˆ†æå¼•æ“ (yfinance ç©©å®šç‰ˆ)", layout="wide")
st.title("ğŸ“Š é«˜æ•ˆå°è‚¡åˆ†æå¼•æ“ (yfinance ç©©å®šç‰ˆ)")
st.markdown("æœ¬ç³»çµ±æ¡ç”¨ **yfinance** ä½œç‚ºæ ¸å¿ƒæ•¸æ“šæºï¼Œçµåˆæœ¬åœ°æ•¸æ“šåº«é€²è¡Œé«˜æ•ˆåˆ†æã€‚æ•¸æ“šå¯æ‰‹å‹•æ›´æ–°ï¼Œæä¾›æ‚¨é–ƒé›»èˆ¬çš„ç¯©é¸é€Ÿåº¦èˆ‡ç©©å®šå¯é çš„æ•¸æ“šå“è³ªã€‚")

# --- Google API é‡‘é‘°è¨­å®š ---
try:
    # ç‚ºäº†æ–¹ä¾¿éƒ¨ç½²ï¼Œæˆ‘å€‘å„ªå…ˆå¾ Streamlit Secrets è®€å–é‡‘é‘°
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
except (KeyError, Exception):
    st.error("éŒ¯èª¤ï¼šè«‹ç¢ºèªä½ çš„ Google API é‡‘é‘°å·²åœ¨ Streamlit Secrets ä¸­æ­£ç¢ºè¨­å®šã€‚")
    st.info("è‹¥åœ¨æœ¬æ©Ÿç«¯é–‹ç™¼ï¼Œè«‹å»ºç«‹ `.streamlit/secrets.toml` æª”æ¡ˆä¸¦è¨­å®šé‡‘é‘°ã€‚")
    st.stop()

# --- è³‡æ–™åº«æª¢æŸ¥èˆ‡æ•¸æ“šè¼‰å…¥ ---
DB_PATH = "tw_stock_data.db"
if not os.path.exists(DB_PATH):
    st.warning(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°æœ¬åœ°è³‡æ–™åº«æª”æ¡ˆ '{DB_PATH}'ã€‚")
    st.info("è«‹é»æ“Šä¸‹æ–¹æŒ‰éˆ•ä¾†ä¸‹è¼‰æœ€æ–°çš„å¸‚å ´æ•¸æ“šä¸¦å»ºç«‹æœ¬åœ°è³‡æ–™åº«ã€‚")
    if st.button("å»ºç«‹/æ›´æ–°æœ¬åœ°å¸‚å ´è³‡æ–™åº«", type="primary", use_container_width=True):
        with st.spinner("æ­£åœ¨åŸ·è¡Œæ•¸æ“šåº«æ›´æ–°ç¨‹åºï¼Œè«‹ç¨å€™..."):
            run_db_update()
        st.success("è³‡æ–™åº«å»ºç«‹æˆåŠŸï¼æ‡‰ç”¨ç¨‹å¼å°‡åœ¨ 3 ç§’å¾Œè‡ªå‹•é‡æ–°è¼‰å…¥ã€‚")
        time.sleep(3)
        st.rerun()
    st.stop()
    
market_data = load_and_merge_data()

# --- RAG æ ¸å¿ƒé‚è¼¯ ---
def get_llm_chain(prompt_template):
    """åˆå§‹åŒ–ä¸¦è¿”å›ä¸€å€‹é…ç½®å¥½çš„ LangChain LLMChainã€‚"""
    model = ChatGoogleGenerativeAI(
        model="gemini-1.5-flash-latest",
        temperature=0.2,
        model_kwargs={"response_format": {"type": "json_object"}}
    )
    prompt = PromptTemplate.from_template(prompt_template)
    return LLMChain(llm=model, prompt=prompt)

def _clean_and_parse_json(raw_text: str):
    """å¾ LLM çš„åŸå§‹è¼¸å‡ºä¸­æ¸…ç†ä¸¦è§£æ JSONã€‚"""
    # ä½¿ç”¨ ì •ê·œ í‘œí˜„ì‹ å°‹æ‰¾è¢« ```json ... ``` åŒ…è£¹çš„å…§å®¹
    match = re.search(r"```(json)?\s*({.*?})\s*```", raw_text, re.DOTALL)
    if match:
        clean_text = match.group(2)
    else:
        # å¦‚æœæ²’æœ‰æ‰¾åˆ° markdown å€å¡Šï¼Œå‰‡å˜—è©¦æ‰¾åˆ°æœ€å¤–å±¤çš„å¤§æ‹¬è™Ÿ
        start_index = raw_text.find('{')
        end_index = raw_text.rfind('}')
        if start_index != -1 and end_index != -1:
            clean_text = raw_text[start_index:end_index+1]
        else:
            raise ValueError("åœ¨ LLM çš„å›æ‡‰ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ JSON ç‰©ä»¶ã€‚")
            
    try:
        return json.loads(clean_text)
    except json.JSONDecodeError as e:
        st.error(f"JSON è§£æå¤±æ•—ï¼Œè«‹æª¢æŸ¥ LLM çš„è¼¸å‡ºæ ¼å¼ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        st.code(raw_text, language="text")
        raise

# --- å ±å‘Šç”Ÿæˆ ---
def generate_portfolio(portfolio_type, risk_profile, investment_amount):
    """æ ¹æ“šä½¿ç”¨è€…è¼¸å…¥ç”ŸæˆæŠ•è³‡çµ„åˆå ±å‘Šã€‚"""
    if portfolio_type in ["ç´”å€‹è‚¡", "æ··åˆå‹"]:
        with st.spinner("æ­¥é©Ÿ 1/2: æ­£åœ¨å¾æœ¬åœ°è³‡æ–™åº«é€²è¡Œé‡åŒ–ç¯©é¸..."):
            if market_data.empty:
                st.error("å¸‚å ´æ•¸æ“šç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œç¯©é¸ã€‚")
                return None
            candidate_df = screen_stocks(market_data, risk_profile)
            if candidate_df.empty:
                st.warning(f"æ ¹æ“šæ‚¨çš„ '{risk_profile}' è¦å‰‡ï¼Œæ‰¾ä¸åˆ°æ»¿è¶³æ‰€æœ‰æ¢ä»¶çš„è‚¡ç¥¨ã€‚è«‹å˜—è©¦æ”¾å¯¬æ¢ä»¶æˆ–æ›´æ–°å¸‚å ´æ•¸æ“šã€‚")
                return None
            # é™åˆ¶å€™é¸åå–®çš„å¤§å°ï¼Œé¿å… Prompt éé•·
            candidate_df = candidate_df.head(50)
            csv_columns = ['stock_id', 'stock_name', 'industry_category', 'pe_ratio', 'pb_ratio', 'yield', 'close_price', 'Positive', 'Negative', 'headline']
            candidate_data_for_llm = candidate_df[csv_columns].to_csv(index=False)

        with st.spinner("æ­¥é©Ÿ 2/2: å·²å®Œæˆé‡åŒ–ç¯©é¸ï¼æ­£åœ¨å°‡å€™é¸åå–®äº¤ç”± AI é€²è¡Œæœ€çµ‚è³ªåŒ–åˆ†æ..."):
            prompt_templates = get_data_driven_prompt_templates()
            chain = get_llm_chain(prompt_templates[portfolio_type])
            input_data = {
                "stock_rules": STOCK_PROMPT_FRAMEWORK, "etf_rules": ETF_PROMPT_FRAMEWORK,
                "risk_profile": risk_profile, "investment_amount": f"{investment_amount:,.0f}",
                "current_date": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥"),
                "candidate_stocks_csv": candidate_data_for_llm
            }
            response = chain.invoke(input_data)
            return _clean_and_parse_json(response['text'])
    else: # ç´” ETF
        with st.spinner("æ­£åœ¨ç‚ºæ‚¨å»ºæ§‹ç´” ETF æŠ•è³‡çµ„åˆ..."):
            prompt_templates = get_data_driven_prompt_templates()
            chain = get_llm_chain(prompt_templates[portfolio_type])
            input_data = {
                "etf_rules": ETF_PROMPT_FRAMEWORK, "risk_profile": risk_profile,
                "investment_amount": f"{investment_amount:,.0f}",
                "current_date": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
            }
            response = chain.invoke(input_data)
            return _clean_and_parse_json(response['text'])

# --- [V2 ç‰ˆ] å ±å‘Šå¯è¦–åŒ– (å·²ä¿®å¾©å››å¤§å•é¡Œ) ---
def display_report(report_data, investment_amount, portfolio_type):
    # ã€å•é¡Œä¸€ï¼šè§£æ±ºæ–¹æ¡ˆã€‘æ“´å……ç”¢æ¥­ä¸­è‹±å°ç…§è¡¨ï¼Œæ¶µè“‹æ›´å¤šå¯èƒ½æ€§
    INDUSTRY_MAP = {
        'Semiconductors': 'åŠå°é«”', 'Computer Hardware': 'é›»è…¦ç¡¬é«”',
        'Financial Services': 'é‡‘èæœå‹™', 'Conglomerates': 'ç¶œåˆä¼æ¥­',
        'Shipping & Ports': 'èˆªé‹èˆ‡æ¸¯å£', 'Telecom Services': 'é›»ä¿¡æœå‹™',
        'Electronic Components': 'é›»å­é›¶çµ„ä»¶', 'Plastics': 'å¡‘è† ',
        'Cement': 'æ°´æ³¥', 'Retail': 'é›¶å”®', 'Textiles': 'ç´¡ç¹”',
        'Food & Beverages': 'é£Ÿå“é£²æ–™', 'Construction': 'ç‡Ÿå»º',
        'Biotechnology': 'ç”Ÿç‰©ç§‘æŠ€', 'Other': 'å…¶ä»–'
    }

    st.header(report_data['summary']['title'])
    st.info(f"å ±å‘Šç”Ÿæˆæ—¥æœŸï¼š{report_data['summary']['generated_date']}")
    st.subheader("ğŸ“ˆ æŠ•è³‡çµ„åˆç¸½è¦½")
    st.write(report_data['summary']['overview'])
    
    st.subheader("ğŸ“Š æ ¸å¿ƒé¢¨éšªæŒ‡æ¨™ (AI ä¼°ç®—)")
    metrics = report_data.get('portfolio_metrics', {})
    metric_labels = {'beta': "Beta å€¼", 'annual_volatility': "å¹´åŒ–æ³¢å‹•ç‡", 'sharpe_ratio': "å¤æ™®æ¯”ç‡"}
    cols = st.columns(len(metrics))
    for i, (key, value) in enumerate(metrics.items()):
        cols[i].metric(metric_labels.get(key, key), value)

    st.write("---")

    # --- æ•¸æ“šæº–å‚™èˆ‡æ¸…æ´— ---
    core_df = pd.DataFrame(report_data.get('core_holdings', []))
    sat_df = pd.DataFrame(report_data.get('satellite_holdings', []))
    # 'holdings' æ˜¯ç‚ºäº†å…¼å®¹ç´”å€‹è‚¡/ç´”ETFçš„æƒ…æ³
    holdings_df = pd.DataFrame(report_data.get('holdings', []))
    
    # æ•´åˆæ‰€æœ‰æŒè‚¡åˆ°ä¸€å€‹ DataFrame
    df = pd.concat([core_df, sat_df, holdings_df], ignore_index=True)

    # ç¢ºä¿ 'weight' æ¬„ä½ç‚ºæ•¸å€¼å‹æ…‹ï¼Œä¸¦ç§»é™¤ç„¡æ•ˆæ¬Šé‡
    df['weight'] = pd.to_numeric(df['weight'], errors='coerce')
    df.dropna(subset=['weight'], inplace=True)
    df = df[df['weight'] > 0].copy()

    if df.empty:
        st.warning("AI ç”Ÿæˆçš„æŠ•è³‡çµ„åˆä¸­æ²’æœ‰æœ‰æ•ˆçš„æŒè‚¡è³‡è¨Šã€‚")
        return
        
    # ã€å•é¡Œä¸‰ï¼šè§£æ±ºæ–¹æ¡ˆã€‘æ¨™æº–åŒ–æ¬Šé‡ï¼Œç¢ºä¿ç¸½å’Œç‚º 100%
    # é€™å€‹æ­¥é©Ÿå¯ä»¥ä¿®æ­£ AI çµ¦å‡ºçš„æ¬Šé‡ç¸½å’Œä¸å®Œå…¨ç­‰æ–¼ 1 æˆ– 100 çš„æƒ…æ³
    total_weight = df['weight'].sum()
    if total_weight > 0:
        df['weight_normalized'] = df['weight'] / total_weight
    else:
        df['weight_normalized'] = 0

    df.sort_values(by='weight_normalized', ascending=False, inplace=True)
    
    # ã€å•é¡Œå››ï¼šè§£æ±ºæ–¹æ¡ˆã€‘ä¿®æ­£è³‡é‡‘åˆ†é…é‚è¼¯ï¼Œé¿å…å› å››æ¨äº”å…¥ç”¢ç”Ÿé©šå˜†è™Ÿ
    df['è³‡é‡‘åˆ†é… (TWD)'] = (df['weight_normalized'] * investment_amount).apply(np.floor).astype(int)
    remainder = investment_amount - df['è³‡é‡‘åˆ†é… (TWD)'].sum()
    # å°‡é¤˜é¡åŠ åˆ°æ¬Šé‡æœ€é«˜çš„æŒè‚¡ä¸Šï¼Œç¢ºä¿è³‡é‡‘å®Œå…¨åˆ†é…
    if not df.empty:
        df.iloc[0, df.columns.get_loc('è³‡é‡‘åˆ†é… (TWD)')] += remainder

    df['æ¬Šé‡ (%)'] = (df['weight_normalized'] * 100)
    
    # ã€å•é¡Œä¸€ï¼šè§£æ±ºæ–¹æ¡ˆã€‘ç¢ºä¿ä¸­æ–‡ç”¢æ¥­æ¬„ä½å­˜åœ¨
    if 'industry' in df.columns:
        df['industry_zh'] = df['industry'].map(INDUSTRY_MAP).fillna(df['industry'])

    # --- åœ–è¡¨ç¹ªè£½ ---
    st.subheader("è¦–è¦ºåŒ–åˆ†æ")
    chart1, chart2 = st.columns(2)

    with chart1:
        fig_pie = px.pie(df, values='weight_normalized', names='name', hole=.3,
                         title='æŒè‚¡æ¬Šé‡åˆ†é…',
                         color_discrete_sequence=px.colors.qualitative.Plotly)
        fig_pie.update_traces(textposition='inside', textinfo='percent+label',
                              hovertemplate='%{label}<br>æ¬Šé‡: %{percent:.2%}')
        fig_pie.update_layout(showlegend=False, margin=dict(l=0, r=0, t=40, b=0))
        st.plotly_chart(fig_pie, use_container_width=True)

    with chart2:
        # ã€å•é¡ŒäºŒï¼šè§£æ±ºæ–¹æ¡ˆã€‘ä¿®æ­£æ··åˆå‹åœ–è¡¨åˆ†é¡é‚è¼¯ï¼Œä½¿å…¶æ›´ç©©å¥
        chart_title = "è³‡ç”¢åˆ†ä½ˆ"
        if portfolio_type == "æ··åˆå‹":
            # ç‚º ETF æ¨™è¨˜ç‚º 'ETF æ ¸å¿ƒ'ï¼Œå€‹è‚¡ä½¿ç”¨ä¸­æ–‡ç”¢æ¥­åˆ¥
            df['chart_category'] = np.where(df['ticker'].str.match(r'^\d{4,6}$'), 
                                           df.get('industry_zh', 'å…¶ä»–å€‹è‚¡'), 
                                           'ETF æ ¸å¿ƒ')
            # é‡å° ETF ticker é€šå¸¸æ˜¯æ•¸å­—çš„ç‰¹æ€§ä¾†å€åˆ†
            is_etf = df['ticker'].str.match(r'^\d{4,6}$') & ('etf_type' in df.columns)
            df['chart_category'] = np.where(is_etf, 'ETF æ ¸å¿ƒ', df.get('industry_zh', 'å…¶ä»–å€‹è‚¡'))

            grouped = df.groupby('chart_category')['weight_normalized'].sum().reset_index()
            chart_title, x_col, y_col = 'è³‡ç”¢é¡åˆ¥åˆ†ä½ˆ (æ··åˆå‹)', 'chart_category', 'weight_normalized'
        
        elif 'industry_zh' in df.columns and df['industry_zh'].notna().any():
            grouped = df.groupby('industry_zh')['weight_normalized'].sum().reset_index()
            chart_title, x_col, y_col = 'ç”¢æ¥­æ¬Šé‡åˆ†ä½ˆ', 'industry_zh', 'weight_normalized'
        
        elif 'etf_type' in df.columns and df['etf_type'].notna().any():
            grouped = df.groupby('etf_type')['weight_normalized'].sum().reset_index()
            chart_title, x_col, y_col = 'ETF é¡å‹åˆ†ä½ˆ', 'etf_type', 'weight_normalized'
        else:
            grouped = None

        if grouped is not None and not grouped.empty:
            fig_bar = go.Figure(data=[go.Bar(
                x=grouped[x_col], y=grouped[y_col],
                text=(grouped[y_col]*100).apply(lambda x: f'{x:.1f}%'), 
                textposition='auto',
                marker_color=px.colors.qualitative.Plotly
            )])
            fig_bar.update_layout(title_text=chart_title, xaxis_title=None, yaxis_title="æ¬Šé‡",
                                  yaxis_tickformat='.0%', margin=dict(l=0, r=0, t=40, b=0))
            st.plotly_chart(fig_bar, use_container_width=True)

    # --- è©³ç´°è¡¨æ ¼ ---
    st.write("---")
    st.subheader("ğŸ“ è©³ç´°æŒè‚¡èˆ‡è³‡é‡‘è¨ˆç•«")
    display_cols = ['ticker', 'name']
    if 'industry_zh' in df.columns and df['industry_zh'].notna().any():
        display_cols.append('industry_zh')
    if 'etf_type' in df.columns and df['etf_type'].notna().any():
        display_cols.append('etf_type')
    display_cols.extend(['æ¬Šé‡ (%)', 'è³‡é‡‘åˆ†é… (TWD)', 'rationale'])
    
    # ç‚ºäº†é¡¯ç¤ºç¾è§€ï¼Œé‡æ–°å‘½åæ¬„ä½
    df_display = df.rename(columns={'ticker': 'ä»£ç¢¼', 'name': 'åç¨±', 'industry_zh': 'ç”¢æ¥­é¡åˆ¥', 'etf_type': 'ETFé¡å‹', 'rationale': 'ç°¡è¦ç†ç”±'})
    
    # ç¢ºä¿è¦é¡¯ç¤ºçš„æ¬„ä½éƒ½å­˜åœ¨æ–¼ DataFrame ä¸­
    final_cols_renamed = [col for col in ['ä»£ç¢¼', 'åç¨±', 'ç”¢æ¥­é¡åˆ¥', 'ETFé¡å‹', 'æ¬Šé‡ (%)', 'è³‡é‡‘åˆ†é… (TWD)', 'ç°¡è¦ç†ç”±'] if col in df_display.columns]

    st.dataframe(df_display[final_cols_renamed], use_container_width=True, hide_index=True,
        column_config={
            "æ¬Šé‡ (%)": st.column_config.ProgressColumn("æ¬Šé‡ (%)", format="%.2f%%", min_value=0, max_value=df_display['æ¬Šé‡ (%)'].max()),
            "è³‡é‡‘åˆ†é… (TWD)": st.column_config.NumberColumn("è³‡é‡‘åˆ†é… (TWD)", format="NT$ %'d"),
            "ç°¡è¦ç†ç”±": st.column_config.TextColumn("ç°¡è¦ç†ç”±", width="large")
        })

def handle_follow_up_question(question, context):
    """è™•ç†å¾ŒçºŒçš„å•ç­”ã€‚"""
    prompt_template = """
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£è‚¡å¸‚æŠ•è³‡çµ„åˆç¶“ç†ã€‚ä½¿ç”¨è€…å·²ç¶“æ”¶åˆ°ä½ å…ˆå‰å»ºç«‹çš„æŠ•è³‡çµ„åˆå ±å‘Šï¼Œç¾åœ¨ä»–æœ‰å¾ŒçºŒå•é¡Œã€‚
    è«‹æ ¹æ“šä½ å…ˆå‰æä¾›çš„å ±å‘Šå…§å®¹ï¼Œä»¥åŠä½¿ç”¨è€…çš„å•é¡Œï¼Œæä¾›ç°¡æ½”ã€å°ˆæ¥­çš„å›ç­”ã€‚
    **å…ˆå‰å ±å‘Šçš„å…§å®¹æ‘˜è¦ (JSON):** {context}
    **ä½¿ç”¨è€…çš„å•é¡Œ:** {question}
    è«‹ç›´æ¥å›ç­”ä½¿ç”¨è€…çš„å•é¡Œï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
    """
    model = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0.5)
    prompt = PromptTemplate.from_template(prompt_template)
    chain = LLMChain(llm=model, prompt=prompt)
    response = chain.invoke({"context": json.dumps(context, ensure_ascii=False), "question": question})
    return response['text']

# --- UI ä¸»æµç¨‹ ---
if 'portfolio_generated' not in st.session_state: st.session_state.portfolio_generated = False
if 'report_data' not in st.session_state: st.session_state.report_data = None
if 'messages' not in st.session_state: st.session_state.messages = []

with st.sidebar:
    st.header("ğŸ‘¤ æ‚¨çš„æŠ•è³‡è¨­å®š")
    portfolio_type_input = st.radio("1. è«‹é¸æ“‡æŠ•è³‡çµ„åˆé¡å‹", ("ç´”å€‹è‚¡", "ç´” ETF", "æ··åˆå‹"), index=2) # é è¨­æ”¹ç‚ºæ··åˆå‹ï¼Œæ–¹ä¾¿æ¸¬è©¦
    risk_profile_input = st.selectbox("2. è«‹é¸æ“‡æ‚¨çš„é¢¨éšªåå¥½", ('ç©æ¥µå‹', 'ç©©å¥å‹', 'ä¿å®ˆå‹'), index=1) # é è¨­æ”¹ç‚ºç©©å¥å‹
    investment_amount_input = st.number_input("3. è«‹è¼¸å…¥æ‚¨é è¨ˆæŠ•å…¥çš„ç¸½è³‡é‡‘ (æ–°å°å¹£)", min_value=10000, value=500000, step=50000)
    
    col1, col2 = st.columns(2)
    with col1:
        analyze_button = st.button("ğŸš€ ç”ŸæˆæŠ•è³‡çµ„åˆ", type="primary", use_container_width=True)
    with col2:
        if st.button("ğŸ”„ æ›´æ–°å¸‚å ´æ•¸æ“š", use_container_width=True):
            with st.spinner("æ­£åœ¨åŸ·è¡Œæ•¸æ“šåº«æ›´æ–°ç¨‹åºï¼Œè«‹ç¨å€™..."):
                run_db_update()
            st.success("æ•¸æ“šåº«æ›´æ–°æˆåŠŸï¼")
            st.rerun()

    st.info("å…è²¬è²æ˜ï¼šæœ¬ç³»çµ±åƒ…ç‚ºAIè¼”åŠ©åˆ†æå·¥å…·ï¼Œæ‰€æœ‰å»ºè­°åƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡æ±ºç­–ä¹‹ä¾æ“šã€‚")

if analyze_button:
    st.session_state.messages = []
    st.session_state.report_data = None
    st.session_state.portfolio_generated = False
    
    if market_data.empty:
        st.error("ç„¡æ³•ç”Ÿæˆå ±å‘Šï¼Œå› ç‚ºå¸‚å ´æ•¸æ“šåº«æ˜¯ç©ºçš„ã€‚è«‹å…ˆæ›´æ–°å¸‚å ´æ•¸æ“šã€‚")
        st.stop()

    report = generate_portfolio(portfolio_type_input, risk_profile_input, investment_amount_input)
    if report:
        st.session_state.report_data = report
        st.session_state.portfolio_generated = True
        st.session_state.investment_amount = investment_amount_input # ä¿å­˜ç•¶æ™‚çš„æŠ•è³‡é‡‘é¡
        st.session_state.portfolio_type = portfolio_type_input # ä¿å­˜ç•¶æ™‚çš„é¡å‹

# å¦‚æœå·²ç¶“ç”Ÿæˆå ±å‘Šï¼Œå‰‡é¡¯ç¤ºå®ƒ
if st.session_state.portfolio_generated and st.session_state.report_data:
    # å¾ session_state è®€å–ï¼Œç¢ºä¿é é¢åˆ·æ–°å¾Œè³‡è¨Šä¾ç„¶å­˜åœ¨
    display_report(st.session_state.report_data, st.session_state.investment_amount, st.session_state.portfolio_type)
    
    st.write("---")
    st.subheader("ğŸ’¬ æå•èˆ‡äº’å‹•èª¿æ•´")
    
    for message in st.session_state.messages:
        with st.chat_message(message["role"]): st.markdown(message["content"])
        
    if prompt := st.chat_input("å°é€™å€‹æŠ•è³‡çµ„åˆæœ‰ä»»ä½•ç–‘å•å—ï¼Ÿ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)
        
        with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
            response = handle_follow_up_question(prompt, st.session_state.report_data)
            st.session_state.messages.append({"role": "assistant", "content": response})
            with st.chat_message("assistant"): st.markdown(response)

elif not market_data.empty:
    st.info("è«‹åœ¨å·¦å´å´é‚Šæ¬„è¨­å®šæ‚¨çš„æŠ•è³‡åå¥½èˆ‡è³‡é‡‘ï¼Œç„¶å¾Œé»æ“Šã€Œç”ŸæˆæŠ•è³‡çµ„åˆã€æŒ‰éˆ•é–‹å§‹åˆ†æã€‚")
