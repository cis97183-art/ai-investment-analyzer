import streamlit as st
import pandas as pd
import google.generativeai as genai
from langchain.chains import LLMChain
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
import plotly.graph_objects as go
import json
from datetime import datetime
import re

# --- å°å…¥æ–°çš„æ¨¡çµ„ ---
from etf_rules import ETF_PROMPT_FRAMEWORK
# [BUG FIX] ä¿®æ­£å°å…¥çš„å‡½å¼åç¨±ï¼Œä¸¦ç§»é™¤ä¸å†éœ€è¦å–®ç¨å°å…¥çš„ STOCK_PROMPT_FRAMEWORK
from prompts import get_data_driven_prompt_templates
from data_fetcher import get_stock_data
from screener import screen_stocks

# --- å°ˆæ¡ˆèªªæ˜ ---
st.set_page_config(page_title="æ•¸æ“šé©…å‹• AI æŠ•è³‡çµ„åˆç³»çµ±", layout="wide")
st.title("ğŸ’¡ æ•¸æ“šé©…å‹• AI æŠ•è³‡çµ„åˆå»ºæ§‹ç³»çµ± (V2)")
st.markdown("æœ¬ç³»çµ±çµåˆ `yfinance` **å³æ™‚å¸‚å ´æ•¸æ“š**é€²è¡Œé‡åŒ–é ç¯©é¸ï¼Œå†ç”± AI æ ¹æ“šå°ˆæ¥­é¢¨éšªæ¡†æ¶ï¼Œå¾é«˜å“è³ªå€™é¸åå–®ä¸­ç‚ºæ‚¨æ‰“é€ å°ˆå±¬æŠ•è³‡çµ„åˆã€‚")


# --- Google API é‡‘é‘°è¨­å®š ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except (KeyError, Exception) as e:
    st.error("éŒ¯èª¤ï¼šè«‹ç¢ºèªä½ çš„ Google API é‡‘é‘°å·²åœ¨ `.streamlit/secrets.toml` ä¸­æ­£ç¢ºè¨­å®šã€‚")
    st.info("è¨­å®šæ•™å­¸ï¼šåœ¨å°ˆæ¡ˆè³‡æ–™å¤¾ä¸­å»ºç«‹ `.streamlit` è³‡æ–™å¤¾ï¼Œä¸¦åœ¨å…¶ä¸­æ–°å¢ `secrets.toml` æª”æ¡ˆï¼Œå…§å®¹ç‚ºï¼š`GOOGLE_API_KEY = \"ä½ çš„é‡‘é‘°\"`")
    st.stop()


# --- RAG æ ¸å¿ƒé‚è¼¯ ---
def get_llm_chain(prompt_template):
    """
    Initializes and returns a LangChain LLMChain.
    Specifies the model to use Gemini-1.5-Flash for speed and cost-effectiveness,
    and sets the response format to JSON.
    """
    model = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest",
                                 temperature=0.2,
                                 # Enforce JSON output format
                                 model_kwargs={"response_format": {"type": "json_object"}})
    prompt = PromptTemplate.from_template(prompt_template)
    chain = LLMChain(llm=model, prompt=prompt)
    return chain

def _clean_and_parse_json(raw_text: str):
    """
    Cleans and parses a JSON string from the LLM's raw output.
    Handles cases where the JSON is wrapped in markdown code blocks.
    """
    # Use regex to find JSON within markdown code blocks (```json ... ```)
    match = re.search(r"```(json)?\s*({.*?})\s*```", raw_text, re.DOTALL)
    if match:
        clean_text = match.group(2)
    else:
        # Fallback for cases where JSON is not in a markdown block
        start_index = raw_text.find('{')
        end_index = raw_text.rfind('}')
        if start_index != -1 and end_index != -1 and end_index > start_index:
            clean_text = raw_text[start_index:end_index+1]
        else:
            clean_text = raw_text # Assume it's already a clean JSON
    try:
        return json.loads(clean_text)
    except json.JSONDecodeError as e:
        st.error("JSON è§£æå¤±æ•—ï¼Œå³ä½¿åœ¨æ¸…ç†å¾Œä¹Ÿæ˜¯å¦‚æ­¤ã€‚")
        st.write("ä»¥ä¸‹æ˜¯ AI å›å‚³çš„åŸå§‹æ–‡å­—ï¼Œé€™å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼š")
        st.code(raw_text, language="text")
        # Re-raise the exception to stop execution if parsing fails
        raise e


# --- å ±å‘Šç”Ÿæˆèˆ‡å¯è¦–åŒ– ---
def generate_portfolio(portfolio_type, risk_profile, investment_amount):
    """[V2] æ ¹æ“šå³æ™‚æ•¸æ“šç¯©é¸ä¸¦ç”ŸæˆæŠ•è³‡å ±å‘Š"""

    # For portfolios containing stocks, first get data and screen it
    if portfolio_type in ["ç´”å€‹è‚¡", "æ··åˆå‹"]:
        with st.spinner("æ­¥é©Ÿ 1/2: æ­£åœ¨å¾ yfinance ç²å–å³æ™‚å¸‚å ´æ•¸æ“šä¸¦é€²è¡Œé‡åŒ–ç¯©é¸..."):
            all_stock_data = get_stock_data()
            if all_stock_data.empty:
                st.error("ç„¡æ³•ç²å–è‚¡ç¥¨æ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–ç¨å¾Œå†è©¦ã€‚")
                return None
            
            candidate_df = screen_stocks(all_stock_data, risk_profile)
            
            if candidate_df.empty:
                st.warning(f"æ ¹æ“šæ‚¨çš„ '{risk_profile}' è¦å‰‡ï¼Œæ‰¾ä¸åˆ°åŒæ™‚æ»¿è¶³æ‰€æœ‰æ¢ä»¶çš„è‚¡ç¥¨ã€‚è«‹å˜—è©¦æ”¾å¯¬æ¢ä»¶æˆ–æ›´æ›é¢¨éšªåå¥½ã€‚")
                return None
            
            # Prepare the screened data as a CSV string for the LLM
            candidate_data_for_llm = candidate_df[['shortName', 'marketCap', 'beta', 'averageVolume', 'trailingPE', 'dividendYield']].to_csv(index=True)

        with st.spinner("æ­¥é©Ÿ 2/2: å·²å®Œæˆé‡åŒ–ç¯©é¸ï¼æ­£åœ¨å°‡å€™é¸åå–®äº¤ç”± AI é€²è¡Œæœ€çµ‚çµ„åˆåˆ†æ..."):
            prompt_templates = get_data_driven_prompt_templates()
            prompt_template = prompt_templates[portfolio_type]
            chain = get_llm_chain(prompt_template)
            
            # The 'stock_rules' are now implicitly part of the template, so we don't need to pass them here
            # But the prompt template expects it, so we need to get it.
            # A better approach would be to refactor prompts.py to not require this.
            # For now, let's re-import it just for this call.
            from prompts import STOCK_PROMPT_FRAMEWORK
            
            input_data = {
                "stock_rules": STOCK_PROMPT_FRAMEWORK,
                "etf_rules": ETF_PROMPT_FRAMEWORK,
                "risk_profile": risk_profile,
                "investment_amount": f"{investment_amount:,.0f}",
                "current_date": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥"),
                "candidate_stocks_csv": candidate_data_for_llm
            }
            response = chain.invoke(input_data)
            return _clean_and_parse_json(response['text'])

    else: # ETF-only portfolio flow
        with st.spinner("æ­£åœ¨ç‚ºæ‚¨å»ºæ§‹ç´” ETF æŠ•è³‡çµ„åˆ..."):
            prompt_templates = get_data_driven_prompt_templates()
            prompt_template = prompt_templates[portfolio_type]
            chain = get_llm_chain(prompt_template)
            input_data = {
                "etf_rules": ETF_PROMPT_FRAMEWORK,
                "risk_profile": risk_profile,
                "investment_amount": f"{investment_amount:,.0f}",
                "current_date": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
            }
            response = chain.invoke(input_data)
            return _clean_and_parse_json(response['text'])


def display_report(report_data, investment_amount):
    """ä»¥åœ–æ–‡ä¸¦èŒ‚çš„æ–¹å¼å‘ˆç¾å ±å‘Š"""
    
    st.header(report_data['summary']['title'])
    st.info(f"å ±å‘Šç”Ÿæˆæ—¥æœŸï¼š{report_data['summary']['generated_date']}")
    
    st.subheader("ğŸ“ˆ æŠ•è³‡çµ„åˆç¸½è¦½")
    st.write(report_data['summary']['overview'])
    
    st.subheader("ğŸ“Š æ ¸å¿ƒé¢¨éšªæŒ‡æ¨™")
    metrics = report_data['portfolio_metrics']
    
    metric_labels = {'beta': "Beta å€¼", 'annual_volatility': "å¹´åŒ–æ³¢å‹•ç‡", 'sharpe_ratio': "å¤æ™®æ¯”ç‡", 'hhi_index': "HHI é›†ä¸­åº¦"}
    
    cols = st.columns(len(metrics))
    for i, (key, value) in enumerate(metrics.items()):
        label = metric_labels.get(key, key.replace('_', ' ').title())
        # Format HHI index as an integer
        if key == 'hhi_index':
            try:
                value = f"{float(value):.0f}"
            except (ValueError, TypeError):
                value = str(value)
        cols[i].metric(label, value)

    st.write("---")

    # Handle different portfolio structures (mixed vs. single-type)
    if 'core_holdings' in report_data:
        core_df = pd.DataFrame(report_data['core_holdings'])
        core_df['é¡å‹'] = 'æ ¸å¿ƒ (ETF)'
        sat_df = pd.DataFrame(report_data['satellite_holdings'])
        sat_df['é¡å‹'] = 'è¡›æ˜Ÿ (å€‹è‚¡)'
        df = pd.concat([core_df, sat_df], ignore_index=True)
        st.subheader("è¦–è¦ºåŒ–åˆ†æï¼šæ•´é«”è³‡ç”¢é…ç½®")
    else:
        df = pd.DataFrame(report_data['holdings'])
        st.subheader("è¦–è¦ºåŒ–åˆ†æ")

    # --- WEIGHT NORMALIZATION FIX ---
    # Ensure 'weight' column is numeric, coercing errors to NaN
    df['weight'] = pd.to_numeric(df['weight'], errors='coerce')
    # Drop rows where weight conversion failed
    df.dropna(subset=['weight'], inplace=True)
    # Re-normalize weights to ensure they sum to 1 (100%)
    if not df.empty and df['weight'].sum() > 0:
        df['weight'] = df['weight'] / df['weight'].sum()
    # --- END FIX ---

    df['è³‡é‡‘åˆ†é… (TWD)'] = (df['weight'] * investment_amount).round(0)
    df['æ¬Šé‡ (%)'] = (df['weight'] * 100).round(2)
    
    chart1, chart2 = st.columns(2)

    with chart1:
        fig_pie = go.Figure(data=[go.Pie(
            labels=df['name'], values=df['weight'], hole=.3,
            textinfo='percent+label', hoverinfo='label+percent+value',
            texttemplate='%{label}<br>%{percent:.1%}',
        )])
        fig_pie.update_layout(title_text='æŒè‚¡æ¬Šé‡åˆ†é…', showlegend=False, margin=dict(l=0, r=0, t=40, b=0))
        st.plotly_chart(fig_pie, use_container_width=True)

    with chart2:
        # Determine the grouping column for the bar chart
        if 'industry' in df.columns and df['industry'].notna().any():
            group_col = 'industry'
            chart_title = 'ç”¢æ¥­æ¬Šé‡åˆ†ä½ˆ'
        elif 'etf_type' in df.columns and df['etf_type'].notna().any():
            group_col = 'etf_type'
            chart_title = 'ETF é¡å‹åˆ†ä½ˆ'
        else:
            group_col = None

        if group_col:
            grouped = df.groupby(group_col)['weight'].sum().reset_index()
            fig_bar = go.Figure(data=[go.Bar(
                x=grouped[group_col], y=grouped['weight'],
                text=(grouped['weight']*100).apply(lambda x: f'{x:.1f}%'),
                textposition='auto',
            )])
            fig_bar.update_layout(title_text=chart_title, xaxis_title=None, yaxis_title="æ¬Šé‡", yaxis_tickformat='.0%', margin=dict(l=0, r=0, t=40, b=0))
            st.plotly_chart(fig_bar, use_container_width=True)
        else:
            st.info("æ­¤æŠ•è³‡çµ„åˆç„¡é©ç”¨çš„åˆ†é¡å¯ä¾›ç¹ªè£½é•·æ¢åœ–ã€‚")

    st.write("---")
    st.subheader("ğŸ“ è©³ç´°æŒè‚¡èˆ‡è³‡é‡‘è¨ˆç•«")

    # Dynamically build the list of columns to display
    display_cols = ['ticker', 'name']
    if 'industry' in df.columns and df['industry'].notna().any(): display_cols.append('industry')
    if 'etf_type' in df.columns and df['etf_type'].notna().any(): display_cols.append('etf_type')
    display_cols.extend(['æ¬Šé‡ (%)', 'è³‡é‡‘åˆ†é… (TWD)', 'rationale'])
    # Ensure we only try to display columns that actually exist in the DataFrame
    final_cols = [col for col in display_cols if col in df.columns]

    st.dataframe(df[final_cols], use_container_width=True, hide_index=True,
        column_config={
            "æ¬Šé‡ (%)": st.column_config.ProgressColumn("æ¬Šé‡ (%)", format="%.2f%%", min_value=0, max_value=100),
            "è³‡é‡‘åˆ†é… (TWD)": st.column_config.NumberColumn("è³‡é‡‘åˆ†é… (TWD)", format="NT$ %'d"),
            "rationale": st.column_config.TextColumn("ç°¡è¦ç†ç”±", width="large")
        })

def handle_follow_up_question(question, context):
    """è™•ç†å¾ŒçºŒå•é¡Œ"""
    prompt_template = """
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£è‚¡å¸‚æŠ•è³‡çµ„åˆç¶“ç†ã€‚ä½¿ç”¨è€…å·²ç¶“æ”¶åˆ°ä½ å…ˆå‰å»ºç«‹çš„æŠ•è³‡çµ„åˆå ±å‘Šï¼Œç¾åœ¨ä»–æœ‰å¾ŒçºŒå•é¡Œã€‚
    è«‹æ ¹æ“šä½ å…ˆå‰æä¾›çš„å ±å‘Šå…§å®¹ï¼Œä»¥åŠä½¿ç”¨è€…çš„å•é¡Œï¼Œæä¾›ç°¡æ½”ã€å°ˆæ¥­çš„å›ç­”ã€‚
    **å…ˆå‰å ±å‘Šçš„å…§å®¹æ‘˜è¦ (JSON):** {context}
    **ä½¿ç”¨è€…çš„å•é¡Œ:** {question}
    è«‹ç›´æ¥å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚
    """
    model = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0.5)
    prompt = PromptTemplate.from_template(prompt_template)
    chain = LLMChain(llm=model, prompt=prompt)
    response = chain.invoke({"context": json.dumps(context, ensure_ascii=False), "question": question})
    return response['text']

# --- UI ---
# Initialize session state variables
if 'portfolio_generated' not in st.session_state: st.session_state.portfolio_generated = False
if 'report_data' not in st.session_state: st.session_state.report_data = None
if 'messages' not in st.session_state: st.session_state.messages = []

with st.sidebar:
    st.header("ğŸ‘¤ æ‚¨çš„æŠ•è³‡è¨­å®š")
    portfolio_type_input = st.radio("1. è«‹é¸æ“‡æŠ•è³‡çµ„åˆé¡å‹", ("ç´”å€‹è‚¡", "ç´” ETF", "æ··åˆå‹"), index=0, captions=("åƒ…å«å€‹è‚¡", "åƒ…å« ETF", "ETF ç‚ºæ ¸å¿ƒï¼Œå€‹è‚¡ç‚ºè¡›æ˜Ÿ"))
    risk_profile_input = st.selectbox("2. è«‹é¸æ“‡æ‚¨çš„é¢¨éšªåå¥½", ('ç©æ¥µå‹', 'ç©©å¥å‹', 'ä¿å®ˆå‹'), index=0, help="ç©æ¥µå‹è¿½æ±‚é«˜å›å ±ï¼›ç©©å¥å‹å¹³è¡¡é¢¨éšªèˆ‡å›å ±ï¼›ä¿å®ˆå‹æ³¨é‡è³‡æœ¬ä¿å€¼ã€‚")
    investment_amount_input = st.number_input("3. è«‹è¼¸å…¥æ‚¨é è¨ˆæŠ•å…¥çš„ç¸½è³‡é‡‘ (æ–°å°å¹£)", min_value=10000, value=100000, step=10000)
    analyze_button = st.button("ğŸš€ ç”Ÿæˆæˆ‘çš„æŠ•è³‡çµ„åˆ", type="primary", use_container_width=True)
    st.info("å…è²¬è²æ˜ï¼šæœ¬ç³»çµ±åƒ…ç‚ºAIè¼”åŠ©åˆ†æå·¥å…·ï¼Œæ‰€æœ‰è³‡è¨Šèˆ‡å»ºè­°åƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡æ±ºç­–çš„ä¾æ“šã€‚æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…è©•ä¼°ã€‚")

if analyze_button:
    # Clear previous chat history and report data on new generation
    st.session_state.messages = []
    st.session_state.report_data = None
    st.session_state.portfolio_generated = False
    
    report = generate_portfolio(portfolio_type_input, risk_profile_input, investment_amount_input)
    if report:
        st.session_state.report_data = report
        st.session_state.portfolio_generated = True

if st.session_state.portfolio_generated:
    display_report(st.session_state.report_data, investment_amount_input)
    st.write("---")
    st.subheader("ğŸ’¬ æå•èˆ‡äº’å‹•èª¿æ•´")
    st.info("å°é€™å€‹æŠ•è³‡çµ„åˆæœ‰ä»»ä½•ç–‘å•å—ï¼Ÿæˆ–è€…æƒ³åšäº›å¾®èª¿ï¼Ÿè«‹åœ¨ä¸‹æ–¹æå‡ºæ‚¨çš„å•é¡Œã€‚")
    
    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]): st.markdown(message["content"])
        
    # Handle new chat input
    if prompt := st.chat_input("ä¾‹å¦‚ï¼šç‚ºä»€éº¼é¸æ“‡ 0050ï¼Ÿ æˆ–è€… å¯ä»¥æŠŠåŠå°é«”å€‹è‚¡æ›æˆåˆ¥çš„å—ï¼Ÿ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)
        
        with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
            response = handle_follow_up_question(prompt, st.session_state.report_data)
            st.session_state.messages.append({"role": "assistant", "content": response})
            with st.chat_message("assistant"): st.markdown(response)
else:
    # Initial message when the app loads
    st.info("è«‹åœ¨å·¦å´å´é‚Šæ¬„è¨­å®šæ‚¨çš„æŠ•è³‡åå¥½èˆ‡è³‡é‡‘ï¼Œç„¶å¾Œé»æ“ŠæŒ‰éˆ•é–‹å§‹ã€‚")
